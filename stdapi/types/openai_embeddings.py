"""Local OpenAI-compatible embeddings types."""

from typing import Literal, Self

from pydantic import AliasChoices, Field, model_validator

from stdapi.types import BaseModelRequestWithExtra, BaseModelResponse


# Ref: openai.types.create_embedding_response.Usage
class Usage(BaseModelResponse):
    """Embedding usage accounting compatible with OpenAI."""

    prompt_tokens: int = Field(
        default=0, ge=0, description="The number of tokens used by the prompt."
    )
    total_tokens: int = Field(
        default=0, ge=0, description="The total number of tokens used by the request."
    )


# Ref: openai.types.embedding.Embedding
class Embedding(BaseModelResponse):
    """Custom embedding model that supports both float lists and base64 strings.

    This extends the OpenAI embedding format to handle base64 encoding properly.
    """

    object: Literal["embedding"] = Field(
        description="The object type, which is always `embedding`."
    )
    index: int = Field(
        description="The index of the embedding in the list of embeddings."
    )
    embedding: list[float] | str = Field(
        description="The embedding vector, which is a list of floats or a base64 string."
    )


# Ref: openai.types.create_embedding_response.CreateEmbeddingResponse
class CreateEmbeddingResponse(BaseModelResponse):
    """Embedding response model."""

    object: Literal["list"] = Field(
        description="The object type, which is always `list`."
    )
    data: list[Embedding] = Field(
        description="The list of embeddings generated by the model."
    )
    model: str = Field(
        description="The name of the model used to generate the embedding."
    )
    usage: Usage = Field(description="The usage information for the request.")


# Ref: openai.types.embedding_create_params.EmbeddingCreateParams
class EmbeddingCreateParams(BaseModelRequestWithExtra):
    """Request body for creating embeddings.

    Validates unsupported values and combinations to match OpenAI behavior.
    """

    input: str | list[str] = Field(
        ...,
        description="Input text to embed, as a single string or an array of strings.\n"
        "For multimodal models, non-text inputs can be passed as base64 data URI (`data:[<mediatype>][;base64],<data>`).\n"
        "Some multimodal models also accept input passed as an S3 URL (`s3://bucket/key`) from a bucket in the same region.\n"
        "To embed multiple inputs in a single request, "
        "pass an array of strings or array of token arrays.\n"
        "Token arrays are UNSUPPORTED on this implementation.",
    )
    model: str = Field(
        ..., description="ID of the model to use.", min_length=1, max_length=255
    )
    dimensions: int | None = Field(
        default=None,
        validation_alias=AliasChoices("dimensions", "embeddingDimension"),
        description=(
            "The number of dimensions the resulting output embeddings should have.\n"
            "Supported by some models only."
        ),
        ge=1,
        le=8192,
    )
    encoding_format: Literal["float", "base64"] | None = Field(
        default="float",
        description=(
            "The format to return the embeddings in.\n"
            "Can be either `float` or `base64`."
        ),
    )
    user: str | None = Field(
        default=None,
        description=(
            "A unique identifier representing your end-user, "
            "which can help to monitor and detect abuse."
        ),
        min_length=1,
        max_length=255,
    )

    @model_validator(mode="after")
    def _unsupported(self) -> Self:
        """Validate unsupported or incompatible embeddings options.

        Raises:
            ValueError: When an unsupported input shape is requested.
        """
        if (
            isinstance(self.input, list)
            and self.input
            and not isinstance(self.input[0], str)
        ):
            msg = "Token array inputs are not supported on this backend. Provide strings instead."
            raise ValueError(msg)
        return self
